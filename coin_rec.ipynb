{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from PIL import Image, ImageTk,ImageDraw, ImageFont\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data,dropout,fully_connected\n",
    "from tflearn.layers.conv import conv_2d,max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a black image, a window\n",
    "img = np.zeros((300,512,3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "\n",
    "# 学習に用いる縮小画像のサイズ\n",
    "sw = 64\n",
    "sh = 64\n",
    "\n",
    "#コインの認識用パラメータ（HチャンネルとSチャンネルとを二値化するための条件）\n",
    "hmin = 34\n",
    "hmax = 115 \n",
    "smin = 30\n",
    "\n",
    "#rectangleの大きさ\n",
    "min_size=900\n",
    "max_size=5000\n",
    "\n",
    "\n",
    "\n",
    "def getImageVector(img):\n",
    "    # 白い領域(ピクセル値が0でない領域)の座標を集める\n",
    "    nonzero = cv2.findNonZero(img)\n",
    "    # その領域を囲う四角形の座標と大きさを取得\n",
    "    xx, yy, ww, hh = cv2.boundingRect(nonzero)\n",
    "    # 白い領域を含む最小の矩形領域を取得\n",
    "    img_nonzero = img[yy:yy+hh, xx:xx+ww]\n",
    "    # 白い領域を(sw, sh)サイズに縮小するための準備\n",
    "    img_small = np.zeros((sh, sw), dtype=np.uint8)\n",
    "    # 画像のアスペクト比を保ったまま、白い領域を縮小してimg_smallにコピーする\n",
    "    if 1*hh < ww*1 and hh > 0:\n",
    "        htmp = int(sw*hh/ww)\n",
    "        if htmp>0:\n",
    "            img_small_tmp = cv2.resize(img_nonzero, (sw, htmp), interpolation=cv2.INTER_LINEAR)\n",
    "            img_small[(sh-htmp)//2:(sh-htmp)//2+htmp, 0:sw] = img_small_tmp\n",
    "    elif 1*hh >= ww*1 and ww > 0:\n",
    "        wtmp = int(sh*ww/hh)\n",
    "        if wtmp>0:\n",
    "            img_small_tmp = cv2.resize(img_nonzero, (wtmp, sh), interpolation=cv2.INTER_LINEAR)\n",
    "            img_small[0:sh, (sw-wtmp)//2:(sw-wtmp)//2+wtmp] = img_small_tmp\n",
    "    # 0...1の範囲にスケーリングしてからリターンする\n",
    "    return np.array([img_small.ravel()/255.])\n",
    "\n",
    "# VideoCapture オブジェクトを取得します\n",
    "capture = cv2.VideoCapture(0)\n",
    "capture.set(5, 15)   # FPS\n",
    "\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\anaconda3\\envs\\tensol\\lib\\site-packages\\tflearn\\initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From c:\\anaconda3\\envs\\tensol\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "net=input_data(shape=[None,64,64,1])\n",
    "net=conv_2d(net,64,5,activation='relu')\n",
    "net=max_pool_2d(net,7)\n",
    "net=conv_2d(net,128,5,activation='relu')\n",
    "net=max_pool_2d(net,7)\n",
    "net=fully_connected(net,256,activation='relu')\n",
    "net=dropout(net,0.5)\n",
    "\n",
    "net=tflearn.fully_connected(net,7,activation='softmax')\n",
    "net=tflearn.regression(net,optimizer='sgd',learning_rate=0.1,loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tflearn.DNN(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Anaconda3\\envs\\tensol\\rec_coin.tflearn\n"
     ]
    }
   ],
   "source": [
    "model.load('./rec_coin.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "\tret,frame = capture.read()\n",
    "\t# 映像データをHSV形式に変換\n",
    "\thsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\t# HSV形式からHチャンネルとSチャンネルの画像を得る\n",
    "\thsv_channels = cv2.split(hsv)\n",
    "\th_channel = hsv_channels[0]\n",
    "\ts_channel = hsv_channels[1]\n",
    "\n",
    "\t# Hチャンネルを平滑化\n",
    "\th_binary_ = cv2.GaussianBlur(h_channel, (5,5), 0)\n",
    "\n",
    "\t# Hチャンネルの二値化画像を作成\n",
    "\t# hmin～hmaxの範囲を255（白）に、それ以外を0（黒）に\n",
    "\tret,h_binary = cv2.threshold(h_binary_, hmax, 255, cv2.THRESH_TOZERO_INV)\n",
    "\tret,h_binary = cv2.threshold(h_binary, hmin, 255, cv2.THRESH_BINARY)\n",
    "\t\n",
    "\tbinary=cv2.bitwise_not(h_binary)\n",
    "\t\n",
    "\t_,contours,_ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\t\n",
    "\timg=np.array(frame)\n",
    "\tprediction_count=0\n",
    "\tresult=[]\n",
    "\tcoin_cnt=0\n",
    "\tcoin_1_cnt=0\n",
    "\tcoin_5_cnt=0\n",
    "\tcoin_10_cnt=0\n",
    "\tcoin_50_cnt=0\n",
    "\tcoin_100_cnt=0\n",
    "\tcoin_500_cnt=0\n",
    "\tsum=0\n",
    "\t\n",
    "\tfor c in contours:\n",
    "\t\tif (cv2.contourArea(c) < min_size or cv2.contourArea(c) >max_size):\n",
    "            \t\tcontinue\n",
    "\t\tx,y,w,h = cv2.boundingRect(c)\n",
    "\t\tcv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "\t\timg = cv2.cvtColor(frame[y:y + h, x:x + w], cv2.COLOR_BGR2GRAY)\n",
    "\t\timg_vector = getImageVector(img)\n",
    "\t\timg_r = np.reshape(img_vector, (1,64,64,1))\n",
    "\t\tprediction=np.array(model.predict(img_r).argmax(axis=1))\n",
    "\t\tif(prediction==6):\n",
    "\t\t\tcontinue\n",
    "\t\tcoin_cnt=coin_cnt+1\n",
    "\t\tif(prediction==0):\n",
    "\t\t\tcoin_1_cnt=coin_1_cnt+1\n",
    "\t\t\tsum=sum+1\n",
    "\t\t\tcv2.putText(frame, '1yen', (x,y-2), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\t\telif(prediction==1):\n",
    "\t\t\tcoin_5_cnt=coin_5_cnt+1\n",
    "\t\t\tsum=sum+5\n",
    "\t\t\tcv2.putText(frame, '5yen', (x,y-2), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\t\telif(prediction==2):\n",
    "\t\t\tcoin_10_cnt=coin_10_cnt+1\n",
    "\t\t\tsum=sum+10\n",
    "\t\t\tcv2.putText(frame, '10yen', (x,y-2), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\t\telif(prediction==3):\n",
    "\t\t\tcoin_50_cnt=coin_50_cnt+1\n",
    "\t\t\tsum=sum+50\n",
    "\t\t\tcv2.putText(frame, '50yen', (x,y-2), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\t\telif(prediction==4):\n",
    "\t\t\tcoin_100_cnt=coin_100_cnt+1\n",
    "\t\t\tsum=sum+100\n",
    "\t\t\tcv2.putText(frame, '100yen', (x,y-2), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\t\telif(prediction==5):\n",
    "\t\t\tcoin_500_cnt=coin_500_cnt+1\n",
    "\t\t\tsum=sum+500\n",
    "\t\t\tcv2.putText(frame, '500yen', (x,y-2), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\tcv2.putText(frame, '1yen:{0} 5yen: {1} 10yen: {2} 50yen:{3} 100yen:{4} 500yen:{5} num: {6} sum: {7} '.format (coin_1_cnt,coin_5_cnt,coin_10_cnt,coin_50_cnt,coin_100_cnt,coin_500_cnt,coin_cnt,sum), (0, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\tcv2.imshow('image',cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\tkey=cv2.waitKey(1) & 0xFF\n",
    "\tif key == ord('q'):\n",
    "\t\tbreak\n",
    "\t\n",
    "\t\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
